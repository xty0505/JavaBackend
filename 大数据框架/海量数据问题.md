# 海量数据问题

海量数据问题一般都是因为数据量过大，无法一次装入内存。

时间复杂度方面，可以使用 BF/Hash/heap/Trie 等数据结构优化，空间复杂度方面可以考虑切分归并/Hash 映射。

一些基础知识：

- 1 btye = 8 bit
- 2^32 = 4G
- 1G = 2^30 = 10.7 亿

## 切分+ hash 映射+快排/归并/堆排

1.给定a, b 两个文件，各存放 50 亿个 url，每个 url 各占 64 字节，内存限制为 4G，如何找出两个文件中共同的 url。

分析：50亿 * 64 = 320G 大小

解决方法：

分别对两个文件进行 hash 分块，将两个文件各自分为 1024 个小文件，这样如果 hash 冲突较少或者说比较均匀则每个文件大约为 300M 左右。

a 文件的所有小文件都和 b 文件对应的小文件迭代一次，每次读入两个文件进入内存，先将 a 的小文件中 url 存入一个 HashMap， 然后检查 b 的小文件中是否有该 url，如果有则保存到一个新的结果文件中。最后将所有的结果文件合并。



2.在海量数据中如何找出重复次数最多的前 100 个数据

解决方法：

首先对文件进行划分，对于文件中的每个数据，计算 hash 值然后划分到不同的小文件中，保证每个小文件能够读入内存。

在每个小文件中利用 HashMap 统计出现最多前 100 个数据，然后将 100 个数据存入磁盘，最后将所有小文件的结果归并排序。



3.在 2.5 亿个整数中找不不重复的整数。

解决方法1：

划分为内存可以读入的小文件，然后每个小文件中统计只出现一次的数，最后合并所有小文件的结果。

解决方法2：

如果内存够 1GB 大小，使用两个 bitmap 数据结构。每个 int 类型的数占 4 字节，总共有 2^32 中可能的整数，因此可以使用两个 2^32 bit 大小的 bitmap，总共大小为 1GB 。

扫描 2.5 亿个整数，bitmap1 对应位置为 0 表示没有出现，为 1 且bitmap2 对应位置为 1 表示出现多次以上，为 1 且 bitmap2 为 0 表示只出现一次。最后遍历两个 bitmap 找到 bitmap1 为 1 且 bitmap2 为 0 的对应位置的数，即为结果。

## BitMap/Bloom Filter

BitMap 通过 bit 位是否为 1 来表示某个状态是否存在。可进行数据的快速**查找、判重、删除**。

适合处理的数据范围应小于 8*2^32 即 4G 。

1.某个文件包含许多电话号码，每个号码有 8 为数字，统计不同号码的个数。

解决方法：

8 位数字最大为 9999 9999，即最多有 100M 个数，若每个数对应一个整数代表其出现的次数，大概需要 400MB 左右的内存空间。因此可以使用一个 400M 位的整数数组来表示每个电话号码的出现次数。

读取文件中的行号码，数组对应位置出现次数加一。